{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Segmentation\n",
    "![Person Segmentation](https://cdn-images-1.medium.com/max/1200/1*UicBY4HeqWEl4l70fTtc6w.png)\n",
    "\n",
    "В этом решении я предлагаю не изобретать велосипед...\n",
    "\n",
    "Немного погуглив можно найти готовые решения на Базе [Mask-RCNN](https://github.com/fizyr/keras-maskrcnn) или [DeepLab v3+](https://github.com/bonlime/keras-deeplab-v3-plus) с уже **предобучеными моделями!**\n",
    "Которые отлично справляються с задачей Сегментации людией (и не только) прямо \"из коробки\". Нам остаеться только адаптировать решение именно под нашу задачу.\n",
    "\n",
    "Что будем делать:\n",
    "> ### Берем сеть Mask-RCNN уже предобученую на датасете COCO и предсказываем маску только для класса Person \n",
    "\n",
    "Это позволит сэкономить нам на обучении сети и сразу получить хороший результат. Звучит не плохо...\n",
    "\n",
    "![smart](http://memesmix.net/media/created/7ncr3w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для начала вглянем на сами картинки в датасете COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-20T06:46:12.719511Z",
     "iopub.status.busy": "2022-03-20T06:46:12.719266Z",
     "iopub.status.idle": "2022-03-20T06:46:12.728023Z",
     "shell.execute_reply": "2022-03-20T06:46:12.727386Z",
     "shell.execute_reply.started": "2022-03-20T06:46:12.719463Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-03-20T06:49:01.062792Z",
     "iopub.status.busy": "2022-03-20T06:49:01.062497Z",
     "iopub.status.idle": "2022-03-20T06:49:01.177075Z",
     "shell.execute_reply": "2022-03-20T06:49:01.176217Z",
     "shell.execute_reply.started": "2022-03-20T06:49:01.062731Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:49:25.504182Z",
     "iopub.status.busy": "2022-03-20T06:49:25.503759Z",
     "iopub.status.idle": "2022-03-20T06:49:26.355149Z",
     "shell.execute_reply": "2022-03-20T06:49:26.35418Z",
     "shell.execute_reply.started": "2022-03-20T06:49:25.504123Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Пример картинки')\n",
    "plt.figure(figsize=(15,10))\n",
    "img = cv2.imread(\"../input/coco2017/train2017/train2017/000000281563.jpg\")\n",
    "label = cv2.imread(\"../input/coco2017/stuffthingmaps_trainval2017/train2017/000000281563.png\")\n",
    "# changing to the BGR format of OpenCV to RGB format for matplotlib\n",
    "plt.subplot(1,3, 1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(1,3, 2)\n",
    "plt.imshow(label)\n",
    "plt.title(\"Label\")\n",
    "dst = cv2.addWeighted(img,0.3,label,0.8,0)\n",
    "plt.subplot(1,3, 3)\n",
    "plt.imshow(dst[:,:,::-1])\n",
    "plt.title(\"Blending\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь Поставим keras_maskrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:49:51.511918Z",
     "iopub.status.busy": "2022-03-20T06:49:51.511593Z",
     "iopub.status.idle": "2022-03-20T06:50:07.092899Z",
     "shell.execute_reply": "2022-03-20T06:50:07.091949Z",
     "shell.execute_reply.started": "2022-03-20T06:49:51.511862Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install keras_maskrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:50:18.610086Z",
     "iopub.status.busy": "2022-03-20T06:50:18.609747Z",
     "iopub.status.idle": "2022-03-20T06:50:29.746319Z",
     "shell.execute_reply": "2022-03-20T06:50:29.745386Z",
     "shell.execute_reply.started": "2022-03-20T06:50:18.610033Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install keras_retinanet==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:50:47.904002Z",
     "iopub.status.busy": "2022-03-20T06:50:47.903676Z",
     "iopub.status.idle": "2022-03-20T06:51:12.331873Z",
     "shell.execute_reply": "2022-03-20T06:51:12.331064Z",
     "shell.execute_reply.started": "2022-03-20T06:50:47.90395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Скачаем веса предобученой модели\n",
    "!wget https://github.com/fizyr/keras-maskrcnn/releases/download/0.2.2/resnet50_coco_v0.2.0.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:51:36.033747Z",
     "iopub.status.busy": "2022-03-20T06:51:36.033442Z",
     "iopub.status.idle": "2022-03-20T06:51:39.302327Z",
     "shell.execute_reply": "2022-03-20T06:51:39.301422Z",
     "shell.execute_reply.started": "2022-03-20T06:51:36.033696Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Копипастим пример\n",
    "у keras_maskrcnn есть отличный [Пример](https://github.com/fizyr/keras-maskrcnn/blob/master/examples/ResNet50MaskRCNN.ipynb)  \n",
    "Просто копируем код из примера, чтоб понять как все работает и посмотреть результаты с нашей картинкой..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:52:09.464262Z",
     "iopub.status.busy": "2022-03-20T06:52:09.46393Z",
     "iopub.status.idle": "2022-03-20T06:52:11.742471Z",
     "shell.execute_reply": "2022-03-20T06:52:11.741728Z",
     "shell.execute_reply.started": "2022-03-20T06:52:09.464213Z"
    }
   },
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_maskrcnn import models\n",
    "from keras_maskrcnn.utils.visualization import draw_mask\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption, draw_annotations\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:52:20.157679Z",
     "iopub.status.busy": "2022-03-20T06:52:20.15738Z",
     "iopub.status.idle": "2022-03-20T06:52:20.872172Z",
     "shell.execute_reply": "2022-03-20T06:52:20.871407Z",
     "shell.execute_reply.started": "2022-03-20T06:52:20.157627Z"
    }
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:53:19.782409Z",
     "iopub.status.busy": "2022-03-20T06:53:19.782112Z",
     "iopub.status.idle": "2022-03-20T06:53:27.611587Z",
     "shell.execute_reply": "2022-03-20T06:53:27.610441Z",
     "shell.execute_reply.started": "2022-03-20T06:53:19.782359Z"
    }
   },
   "outputs": [],
   "source": [
    "# adjust this to point to your downloaded/trained model\n",
    "model_path = os.path.join('./','resnet50_coco_v0.2.0.h5')\n",
    "\n",
    "# load retinanet model\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "#print(model.summary())\n",
    "\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'person',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:53:37.379928Z",
     "iopub.status.busy": "2022-03-20T06:53:37.379476Z",
     "iopub.status.idle": "2022-03-20T06:53:43.22056Z",
     "shell.execute_reply": "2022-03-20T06:53:43.219784Z",
     "shell.execute_reply.started": "2022-03-20T06:53:37.379726Z"
    }
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "image = read_image_bgr('../input/coco2017/train2017/train2017/000000281563.jpg')\n",
    "\n",
    "# copy to draw on\n",
    "draw = image.copy()\n",
    "draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# preprocess image for network\n",
    "image = preprocess_image(image)\n",
    "image, scale = resize_image(image)\n",
    "\n",
    "# process image\n",
    "start = time.time()\n",
    "outputs = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "print(\"processing time: \", time.time() - start)\n",
    "\n",
    "boxes  = outputs[-4][0]\n",
    "scores = outputs[-3][0]\n",
    "labels = outputs[-2][0]\n",
    "masks  = outputs[-1][0]\n",
    "\n",
    "# correct for image scale\n",
    "boxes /= scale\n",
    "\n",
    "# visualize detections\n",
    "for box, score, label, mask in zip(boxes, scores, labels, masks):\n",
    "    if score < 0.5:\n",
    "        break\n",
    "\n",
    "    color = label_color(label)\n",
    "    \n",
    "    b = box.astype(int)\n",
    "    draw_box(draw, b, color=color)\n",
    "    \n",
    "    mask = mask[:, :, label]\n",
    "    draw_mask(draw, b, mask, color=label_color(label))\n",
    "    \n",
    "    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "    #draw_caption(draw, b, caption)\n",
    "    \n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(draw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотриться не плохо, давай теперь вынесем только маску и сравним с эталоном.\n",
    "для этого чуть модифицируем код из примера (уберем боксы и оставим только маску) и завернем все в функцию чтоб было удобно с этим работать в дальнейшем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:54:24.661446Z",
     "iopub.status.busy": "2022-03-20T06:54:24.661099Z",
     "iopub.status.idle": "2022-03-20T06:54:24.703365Z",
     "shell.execute_reply": "2022-03-20T06:54:24.702513Z",
     "shell.execute_reply.started": "2022-03-20T06:54:24.661391Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_get (image, model, THRESHOLD=0.5):\n",
    "    \n",
    "    #image = read_image_bgr(image)\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    outputs = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    #print(\"processing time: \", time.time() - start)\n",
    "    draw = np.zeros((draw.shape[0], draw.shape[1], 3), np.uint8)\n",
    "\n",
    "    boxes  = outputs[-4][0]\n",
    "    scores = outputs[-3][0]\n",
    "    labels = outputs[-2][0]\n",
    "    masks  = outputs[-1][0]\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # visualize detections\n",
    "    #draw = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n",
    "    for box, score, label, mask in zip(boxes, scores, labels, masks):\n",
    "        if score < THRESHOLD:\n",
    "            break\n",
    "        b = box.astype(int)\n",
    "        #draw_box(draw, b, color=color)\n",
    "        if label == 0:\n",
    "            mask = mask[:, :, label]\n",
    "            #draw = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n",
    "            draw_mask(draw, b, mask, color=label_color(label))\n",
    "\n",
    "        #caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        #draw_caption(draw, b, caption)\n",
    "\n",
    "    mask_out = (draw[:, :, 0] > THRESHOLD).astype(np.uint8)\n",
    "    return(mask_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:54:33.079776Z",
     "iopub.status.busy": "2022-03-20T06:54:33.079473Z",
     "iopub.status.idle": "2022-03-20T06:54:34.076949Z",
     "shell.execute_reply": "2022-03-20T06:54:34.076012Z",
     "shell.execute_reply.started": "2022-03-20T06:54:33.079713Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Сразу сравним с эталоном')\n",
    "image = read_image_bgr('../input/coco2017/train2017/train2017/000000281563.jpg')\n",
    "mask_out = mask_get(image, model, THRESHOLD=0.5)\n",
    "plt.figure(figsize=(15, 15))\n",
    "label = cv2.imread(\"../input/coco2017/stuffthingmaps_trainval2017/train2017/000000281563.png\")\n",
    "plt.subplot(1,2, 1)\n",
    "plt.imshow(mask_out)\n",
    "plt.title(\"Predict\")\n",
    "plt.subplot(1,2, 2)\n",
    "plt.imshow(label[:, :, 0] < 0.5)\n",
    "plt.title(\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Даже на таком сложном примере получаем неплохой Результат! \n",
    "> Кстати, ты заметил что разметка самого датасета COCO далека от идеала, и в некоторых местах модель это делает даже лучше!  \n",
    "> Это известная плоблема этого датасета, по этому для сегментации людей используют специализированные датасеты (Например [Supervisely Person Dataset](https://hackernoon.com/releasing-supervisely-person-dataset-for-teaching-machines-to-segment-humans-1f1fc1f28469)), но для обучения нам и COCO сойдет\n",
    "\n",
    "Нам осталось только сделать предикт на каждую картинку и записать в submission в нужном формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:54:59.888702Z",
     "iopub.status.busy": "2022-03-20T06:54:59.888405Z",
     "iopub.status.idle": "2022-03-20T06:55:00.141608Z",
     "shell.execute_reply": "2022-03-20T06:55:00.140876Z",
     "shell.execute_reply.started": "2022-03-20T06:54:59.888648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Из sample-submission читаем по каким именно картинкам нам нужно сделать предсказание\n",
    "sample_submission = pd.read_csv('../input/sf-dl-person-segmentation/sample-submission.csv')\n",
    "sample_submission.info()\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:55:13.106388Z",
     "iopub.status.busy": "2022-03-20T06:55:13.106089Z",
     "iopub.status.idle": "2022-03-20T06:55:13.145445Z",
     "shell.execute_reply": "2022-03-20T06:55:13.144739Z",
     "shell.execute_reply.started": "2022-03-20T06:55:13.106338Z"
    }
   },
   "outputs": [],
   "source": [
    "# кодирование маски в EncodedPixels\n",
    "def mask_to_rle(mask):\n",
    "    mask_flat = mask.flatten('F')\n",
    "    flag = 0\n",
    "    rle_list = list()\n",
    "    for i in range(mask_flat.shape[0]):\n",
    "        if flag == 0:\n",
    "            if mask_flat[i] == 1:\n",
    "                flag = 1\n",
    "                starts = i+1\n",
    "                rle_list.append(starts)\n",
    "        else:\n",
    "            if mask_flat[i] == 0:\n",
    "                flag = 0\n",
    "                ends = i\n",
    "                rle_list.append(ends-starts+1)\n",
    "    if flag == 1:\n",
    "        ends = mask_flat.shape[0]\n",
    "        rle_list.append(ends-starts+1)\n",
    "    #sanity check\n",
    "    if len(rle_list) % 2 != 0:\n",
    "        print('NG')\n",
    "    if len(rle_list) == 0:\n",
    "        rle = np.nan\n",
    "    else:\n",
    "        rle = ' '.join(map(str,rle_list))\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Осталось дело за малым, \n",
    "# пройтись по списку картинок и сделать предикты с дальнейшим их кодированием в EncodedPixels\n",
    "# Это займет значительное время (около 8 часов)...\n",
    "\n",
    "THRESHOLD=0.45  # с уровнем от которого считаеться маска - можно поиграться\n",
    "\n",
    "submit_rle_arr = []\n",
    "\n",
    "for img_id in tqdm_notebook(sample_submission.ImageId.values):\n",
    "    image = read_image_bgr(f'../input/coco2017/val2017/{img_id}')\n",
    "    mask_out = mask_get(image, model, THRESHOLD=THRESHOLD)\n",
    "    rle = mask_to_rle(mask_out)\n",
    "    submit_rle_arr.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['EncodedPixels'] = submit_rle_arr\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вот и все решение!**\n",
    "\n",
    "### Как можно улучшить результат:\n",
    "1. Подобрать THRESHOLD\n",
    "2. Дообучить модель для более точной разметки только класса Person\n",
    "3. Сделать тоже самое например на [DeepLab v3+](https://github.com/bonlime/keras-deeplab-v3-plus) и усреднить результаты (те сделать ансамбль моделей, этож kaggle, куда тут без этого ;) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
